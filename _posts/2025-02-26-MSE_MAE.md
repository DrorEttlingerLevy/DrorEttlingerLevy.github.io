---
title: 'Metrics in Linear Regression'
date: 2025-02-26
permalink: /posts/2025/02/MSE_MAE/
---

Understanding model performance metrics is key in linear regressionüìà. `MSE` highlights large errors but is sensitive to outliers, while `MAE` provides a more intuitive measure of average error, making it less influenced by extreme values. `RMSE` üîç bridges the gap, preserving `MSE‚Äôs` sensitivity while keeping results in the original scale. In our car price prediction example, a high `RMSE/MAE` ratio suggests heteroscedasticity, indicating that linear regression might not be the best fit. Ultimately, choosing the right metric depends on your business needs‚Äîwhether minimizing big errors or getting a clear picture of average performance matters more.

# Understanding Model Performance Metrics in Linear Regression: A Comprehensive Guide üìä

## Introduction
When building machine learning models, checking how well they perform is key to knowing if our predictions actually make sense. With linear regression, we assume relationships are linear and that observations are independent. The evaluation metrics we use should align with these assumptions while also giving us a clear way to measure errors in the same scale as our target variable.

Two common metrics, Mean Squared Error (MSE) and Mean Absolute Error (MAE), help us understand how far off our predictions are. But in many cases, Root Mean Squared Error (RMSE) is even more useful since it gives more weight to larger errors, making it a better indicator of overall model performance.

![My helpful screenshot](/images/9ljo6e.jpg)


## Core Metrics and Their Mathematical Foundation üéØ

### Mean Squared Error (MSE)
MSE‚Äôs squared nature makes it extra sensitive to outliers, meaning it reacts strongly when the model makes big mistakes. This can be helpful because it highlights large errors more clearly, making them harder to ignore. But it also means that just a few outliers can significantly impact the overall error, which is something to keep in mind when choosing the right metric for your model.

$$ MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2 $$

```python
import numpy as np

def calculate_mse(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)
```

### Mean Absolute Error (MAE)
MAE gives a more intuitive sense of error since it represents the average absolute difference between predictions and actual values. Unlike MSE, it‚Äôs less sensitive to outliers, making it a great choice when you want a clearer picture of typical model performance without big errors skewing the results.

$$ MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i| $$

```python
def calculate_mae(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))
```

### Root Mean Squared Error (RMSE)
RMSE bridges the gap between MSE and MAE by combining MSE‚Äôs sensitivity to outliers with the interpretability of MAE, keeping the error in the same scale as the target variable. Under linear regression assumptions, it also serves as an estimate of the standard deviation of residuals, making it a useful measure for understanding overall model performance.

$$ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2} $$

```python
def calculate_rmse(y_true, y_pred):
    return np.sqrt(calculate_mse(y_true, y_pred))
```

## Real-World Application: Car Price Prediction Analysis
In our car price prediction example, we observe MSE = 7,214 (dollars¬≤), MAE = 21 (dollars), and RMSE = 84 (dollars).  These numbers tell an interesting story about our model‚Äôs performance. The MAE of $21 means that, on average, our predictions are off by $21. But the much higher RMSE of $84 suggests that while the model does well in most cases, it sometimes makes much larger mistakes.

Looking at the relationship between these metrics gives us even deeper insights. The RMSE/MAE ratio of 4 hints at heteroscedasticity in our predictions‚Äîmeaning the errors might not be evenly distributed. This could be a sign that a linear regression model isn‚Äôt the best fit, and we might want to explore other approaches.


## Conclusion
Understanding these metrics is key to validating and assessing model performance. In our example, the big gap between MAE and RMSE suggests that while the model works well for typical cases, it struggles with extreme ones. This might lead us to consider data transformations or even a different modeling approach.

Ultimately, the right metric depends on what matters most for your application. If big errors are costly, RMSE might be the better choice. If you need a simple, interpretable measure, MAE could be more useful. It all comes down to the business question at hand, the importance of model assumptions, and whether outliers play a big role in your data. The better we understand these metrics, the smarter decisions we can make about improving our models.